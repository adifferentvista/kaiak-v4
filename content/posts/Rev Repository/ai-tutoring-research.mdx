---
title: "AI Tutoring: What the Research Actually Says"
description: "Headlines claim AI tutoring matches human instruction, but the Harvard study used custom AI with elite students vs. self-study—not ChatGPT vs. human tutors. Here's what research actually shows and what questions to ask vendors."
date: "2026-01-20"
pillar: "education"
contentType: "evergreen"
readTime: "9 min read"
featured: false
keywords: ["AI tutoring research", "AI tutoring effectiveness", "intelligent tutoring systems", "AI tutor vs human tutor"]
interlinks:
  - "why-ai-skills-are-no-longer-optional"
  - "ai-critical-thinking"
  - "school-leaders-guide-ai-2026"
---

<div style={{background: 'linear-gradient(135deg, #fef3c7 0%, #fde68a 100%)', padding: '24px', borderRadius: '12px', marginBottom: '2rem', borderLeft: '4px solid #d97706'}}>
<div style={{fontSize: '1.1rem', lineHeight: '1.7', color: '#92400e'}}>
<strong style={{fontSize: '1.3rem'}}>The headline vs. reality gap:</strong> When students used standard ChatGPT for math practice, they scored <strong>17% worse</strong> on tests than students who practiced without AI. But a carefully designed AI tutor helped Harvard students learn <strong>twice as much</strong> in less time. The difference? Pedagogical design—not AI sophistication.
</div>
</div>

AI tutoring headlines are misleading. The [Harvard study](https://www.nature.com/articles/s41598-025-97652-6) showing AI tutoring "as effective as human instruction" used custom-designed AI (not ChatGPT) with Harvard undergraduates (not K-12 students) compared to active learning (not human tutors). A [systematic review of 28 K-12 studies](https://www.nature.com/articles/s41539-025-00320-7) concludes AI tutoring "should be considered complementary tools rather than replacements for educators." Here's what research actually shows—and what questions to ask before buying.

## What Did the Harvard AI Tutoring Study Actually Find?

In June 2025, Harvard researchers published a [randomized controlled trial in Scientific Reports](https://www.nature.com/articles/s41598-025-97652-6) showing AI tutoring outperformed traditional active learning in physics courses, with effect sizes between **0.73 and 1.3 standard deviations**. Those numbers are impressive—but three critical details change the interpretation.

<div style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))', gap: '16px', margin: '2rem 0'}}>
<div style={{background: '#fef2f2', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #dc2626'}}>
<div style={{fontSize: '0.85rem', fontWeight: '600', color: '#dc2626', marginBottom: '8px'}}>WHAT HEADLINES IMPLY</div>
<div style={{fontWeight: '700', marginBottom: '8px'}}>ChatGPT-style AI</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>Generic chatbot anyone can use</div>
</div>
<div style={{background: '#f0fdf4', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #16a34a'}}>
<div style={{fontSize: '0.85rem', fontWeight: '600', color: '#16a34a', marginBottom: '8px'}}>WHAT WAS ACTUALLY TESTED</div>
<div style={{fontWeight: '700', marginBottom: '8px'}}>Custom "PS2 Pal" system</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>Scaffolded questioning, targeted feedback, pre-written solutions, structured sequences</div>
</div>
</div>

<div style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))', gap: '16px', margin: '2rem 0'}}>
<div style={{background: '#fef2f2', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #dc2626'}}>
<div style={{fontSize: '0.85rem', fontWeight: '600', color: '#dc2626', marginBottom: '8px'}}>WHAT HEADLINES IMPLY</div>
<div style={{fontWeight: '700', marginBottom: '8px'}}>Typical students</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>K-12 or general population</div>
</div>
<div style={{background: '#f0fdf4', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #16a34a'}}>
<div style={{fontSize: '0.85rem', fontWeight: '600', color: '#16a34a', marginBottom: '8px'}}>WHAT WAS ACTUALLY TESTED</div>
<div style={{fontWeight: '700', marginBottom: '8px'}}>194 Harvard undergraduates</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>Highly motivated, academically strong, self-selected into physics course</div>
</div>
</div>

<div style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))', gap: '16px', margin: '2rem 0'}}>
<div style={{background: '#fef2f2', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #dc2626'}}>
<div style={{fontSize: '0.85rem', fontWeight: '600', color: '#dc2626', marginBottom: '8px'}}>WHAT HEADLINES IMPLY</div>
<div style={{fontWeight: '700', marginBottom: '8px'}}>Human tutors</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>One-on-one expert instruction</div>
</div>
<div style={{background: '#f0fdf4', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #16a34a'}}>
<div style={{fontSize: '0.85rem', fontWeight: '600', color: '#16a34a', marginBottom: '8px'}}>WHAT WAS ACTUALLY TESTED</div>
<div style={{fontWeight: '700', marginBottom: '8px'}}>Active learning classroom</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>Group instruction with peer work—not one-on-one tutoring</div>
</div>
</div>

The researchers themselves note the comparison was between "an AI tutor" and "an active learning class"—not between AI and human tutoring. The pedagogical design of the AI mattered enormously. As the study authors state, "AI chatbots are generally designed to be helpful, not to promote learning."

<Callout type="warning" title="The headline trap">
Vendors cite this study to sell products that bear little resemblance to what was tested. Ask: "Is your system designed like the one in the Harvard study?" The answer is almost always no.
</Callout>

## What Happens When Students Use Regular ChatGPT?

A [University of Pennsylvania study published in PNAS](https://www.pnas.org/doi/10.1073/pnas.2422633122) (June 2025) tested nearly 1,000 Turkish high school students using AI for math practice. The results were sobering.

Students using standard ChatGPT solved **48% more practice problems correctly**—but then scored **17% worse** on the subsequent test than students who practiced without any AI assistance. The researchers titled their paper "Generative AI Can Harm Learning" and found students were using the chatbot as a "crutch," simply asking for answers rather than working through problems.

Even a modified "GPT Tutor" with guardrails designed to scaffold learning (giving hints rather than answers) produced no significant improvement over practicing alone. The researchers concluded that without careful design, "generative AI can substantially inhibit learning."

This finding matters because most commercial "AI tutoring" products are closer to ChatGPT than to Harvard's carefully engineered PS2 Pal system.

## What Do Systematic Reviews Across Many Studies Show?

When researchers analyze many studies rather than single experiments, the picture is more nuanced.

A [May 2025 systematic review](https://www.nature.com/articles/s41539-025-00320-7) examining 28 K-12 studies with 4,597 students found that effects of intelligent tutoring systems on learning are "generally positive but are found to be **mitigated when compared to non-intelligent tutoring systems**." AI tutoring works—but often not much better than well-designed non-AI alternatives.

The same review concluded that intelligent tutoring systems "should be considered **complementary tools rather than replacements** for educators." Most effective implementations combine AI with human guidance.

Notably, "none of the reviewed studies seriously considered AI ethics." Data privacy, algorithmic bias, and appropriate use questions are largely ignored in effectiveness research.

## What Does Work? Evidence from ASSISTments

[ASSISTments](https://www.evidenceforessa.org/program/assistments/), a free math homework platform, provides one of the strongest evidence bases for AI-assisted learning in K-12. Two large randomized controlled trials earned it the highest [ESSA Tier 1 evidence rating](https://www.evidenceforessa.org/program/assistments/).

A North Carolina study with nearly 6,000 seventh-graders found students using ASSISTments scored significantly higher on state math tests with an effect size of **0.10**—equivalent to about 31% of a typical year's learning gains. Effects persisted one year after the intervention ended.

What makes ASSISTments different from generic AI tutoring? It provides immediate feedback on homework, gives teachers real-time reports on student performance, and integrates directly with classroom instruction. The AI assists teachers rather than replacing them.

## When Does AI Tutoring Help?

<div style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(250px, 1fr))', gap: '16px', margin: '2rem 0'}}>
<div style={{background: '#f0fdf4', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #16a34a'}}>
<div style={{fontWeight: '700', marginBottom: '8px', color: '#16a34a'}}>Practice & Reinforcement</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>AI provides unlimited practice with immediate feedback—hard for teachers at scale</div>
</div>
<div style={{background: '#f0fdf4', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #16a34a'}}>
<div style={{fontWeight: '700', marginBottom: '8px', color: '#16a34a'}}>Standardized Content</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>Math procedures, grammar rules, basic facts have clear right/wrong answers AI handles well</div>
</div>
<div style={{background: '#f0fdf4', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #16a34a'}}>
<div style={{fontWeight: '700', marginBottom: '8px', color: '#16a34a'}}>Teacher Integration</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>AI handles drill; teachers use data to inform instruction and handle motivation/relationships</div>
</div>
<div style={{background: '#f0fdf4', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #16a34a'}}>
<div style={{fontWeight: '700', marginBottom: '8px', color: '#16a34a'}}>Extended Time</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>AI doesn't judge, doesn't tire, doesn't make struggling students feel like a burden</div>
</div>
</div>

The pattern: AI tutoring works best as a supplement, not a replacement—particularly for practice, reinforcement, and personalized pacing.

## When Does AI Tutoring Fail—Or Cause Harm?

<div style={{display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(250px, 1fr))', gap: '16px', margin: '2rem 0'}}>
<div style={{background: '#fef2f2', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #dc2626'}}>
<div style={{fontWeight: '700', marginBottom: '8px', color: '#dc2626'}}>Without Human Guidance</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>Students don't know what to work on, how to use the system, or when they're ready to move on</div>
</div>
<div style={{background: '#fef2f2', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #dc2626'}}>
<div style={{fontWeight: '700', marginBottom: '8px', color: '#dc2626'}}>For Developing Understanding</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>AI helps students get correct answers; less clear it helps them understand why</div>
</div>
<div style={{background: '#fef2f2', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #dc2626'}}>
<div style={{fontWeight: '700', marginBottom: '8px', color: '#dc2626'}}>As a Replacement</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>AI tutoring alone rarely works; the UPenn study showed it can actually harm learning</div>
</div>
<div style={{background: '#fef2f2', padding: '20px', borderRadius: '8px', borderLeft: '4px solid #dc2626'}}>
<div style={{fontWeight: '700', marginBottom: '8px', color: '#dc2626'}}>Open-Ended Work</div>
<div style={{fontSize: '0.9rem', color: '#666'}}>AI struggles with reasoning that lacks clear right/wrong answers</div>
</div>
</div>

A student might improve test scores with AI tutoring while developing only shallow understanding. Performance gains don't always equal learning gains.

<div style={{background: '#f8fafc', padding: '24px', borderRadius: '8px', margin: '2rem 0'}}>
<div style={{marginBottom: '16px'}}>
<span style={{background: '#fee2e2', color: '#dc2626', padding: '4px 12px', borderRadius: '4px', fontSize: '0.85rem', fontWeight: '600'}}>BEFORE</span>
<div style={{margin: '8px 0 0 0', fontSize: '1rem', color: '#374151'}}>"Let's adopt AI tutoring to solve our differentiation challenges."</div>
</div>
<div>
<span style={{background: '#dcfce7', color: '#16a34a', padding: '4px 12px', borderRadius: '4px', fontSize: '0.85rem', fontWeight: '600'}}>AFTER</span>
<div style={{margin: '8px 0 0 0', fontSize: '1rem', color: '#374151'}}>"Let's use AI tutoring to provide additional practice time, while teachers focus on conceptual instruction and relationship-building."</div>
</div>
</div>

## What Questions Should You Ask AI Tutoring Vendors?

When vendors make effectiveness claims, demand specifics:

**"What does your evidence show?"**
Require specific studies with specific populations. "Research shows..." isn't good enough. Which research? What populations? What comparison conditions? The [Wharton researchers](https://knowledge.wharton.upenn.edu/article/without-guardrails-generative-ai-can-harm-education/) found that students overestimate their learning when using AI—so don't trust self-reported satisfaction.

**"How was the AI designed pedagogically?"**
A chatbot isn't a tutor. What instructional principles are built in? How does it scaffold learning? How does it handle misconceptions? The Harvard PS2 Pal included pre-written expert solutions to avoid hallucinations—does the vendor's product?

**"What teacher integration do you recommend?"**
If the answer is "none needed," be skeptical. The [best evidence from ESSA-rated programs](https://www.evidenceforessa.org/program/assistments/) supports AI tutoring with teacher involvement and dashboard reporting.

**"What data do you collect, and how is it protected?"**
AI tutoring systems collect extensive data about student performance, behavior, and patterns. Understand what's collected and who has access.

**"What happens when students get stuck or frustrated?"**
Good systems detect and respond to student affect. Cheap ones just keep presenting problems regardless of student state.

<Callout type="tip" title="The pilot mindset">
The best way to evaluate AI tutoring isn't reading vendor materials—it's running a small pilot with careful measurement. Let teachers try the tool with a few students and gather real data before scaling.
</Callout>

## What's the Honest Bottom Line?

AI tutoring can work—not as magic, not as a teacher replacement, but as a supplement with genuine value for practice, reinforcement, and personalized pacing.

If you're considering AI tutoring tools:

1. Look for systems designed with learning principles built in—not just chatbots with education branding
2. Demand evidence from populations similar to yours—Harvard undergrads aren't typical K-12 students
3. Require clear integration with teacher instruction—the evidence for standalone AI tutoring is weak
4. Be skeptical of vendor claims—even well-designed AI tutors show modest effect sizes (0.10-0.20) in real-world K-12 settings
5. Pilot before you scale—and measure outcomes not tied to the tutoring platform itself

The pedagogical design matters more than the AI sophistication. A well-designed non-AI system often outperforms a poorly-designed AI one—and as the UPenn study showed, poorly-designed AI can actually harm learning.

---

## Frequently Asked Questions

### Can ChatGPT work as a tutor?

Generic ChatGPT is designed to be helpful, not pedagogically effective. It gives answers rather than scaffolding learning. The [UPenn research](https://www.pnas.org/doi/10.1073/pnas.2422633122) showed students using ChatGPT for math practice scored 17% worse on tests—they were using it as a "crutch" rather than engaging in productive struggle. Purpose-built AI tutoring systems with learning principles built in can outperform generic chatbots, but most commercial "AI tutoring" products are closer to ChatGPT than to what research studies actually tested.

### What effect sizes should I look for in vendor research?

An effect size of 0.4 is considered educationally meaningful. The Harvard study showed 0.73-1.3, but under very specific conditions with elite students. Real-world K-12 implementations like [ASSISTments](https://www.evidenceforessa.org/program/assistments/) show more modest but still meaningful effect sizes around 0.10-0.18. Be skeptical of any vendor claiming Harvard-level results with general K-12 populations using generic AI.

### Should we use AI tutoring for students who are behind?

Potentially yes—for targeted practice on specific skills. But struggling students often need the relationship and motivation that human teachers provide. AI tutoring as catch-up support works better than AI tutoring as remediation replacement. The [systematic review](https://www.nature.com/articles/s41539-025-00320-7) found AI tutoring most effective when combined with teacher involvement.

### What about AI tutoring for advanced students?

Advanced students often need challenge and creativity that AI handles poorly. AI tutoring can provide extra practice, but enrichment usually requires human guidance for open-ended exploration.

### How do we know if AI tutoring is actually helping our students learn?

Don't rely on the AI's own metrics. Compare performance on assessments not tied to the tutoring system. Look for transfer—can students apply learning in new contexts? Performance gains within the AI system don't always translate to genuine understanding. The UPenn study found students performed great during AI-assisted practice but poorly on independent tests.

---

## References

1. [AI Tutoring Outperforms Active Learning](https://www.nature.com/articles/s41598-025-97652-6) - Kestin et al., Scientific Reports (June 2025)
2. [Generative AI Without Guardrails Can Harm Learning](https://www.pnas.org/doi/10.1073/pnas.2422633122) - Bastani et al., PNAS (June 2025)
3. [Systematic Review of AI-Driven ITS in K-12](https://www.nature.com/articles/s41539-025-00320-7) - Létourneau et al., npj Science of Learning (May 2025)
4. [ASSISTments ESSA Evidence](https://www.evidenceforessa.org/program/assistments/) - Evidence for ESSA
5. [Without Guardrails, Generative AI Can Harm Education](https://knowledge.wharton.upenn.edu/article/without-guardrails-generative-ai-can-harm-education/) - Knowledge at Wharton (August 2024)
6. [Kids Who Use ChatGPT Do Worse on Tests](https://hechingerreport.org/kids-chatgpt-worse-on-tests/) - Hechinger Report (September 2024)
7. [AI Tutor Helped Harvard Students Learn More Physics](https://hechingerreport.org/proof-points-ai-tutor-harvard-physics/) - Hechinger Report (September 2024)
8. [The Algorithmic Turn: Emerging Evidence on AI Tutoring](https://carlhendrick.substack.com/p/the-algorithmic-turn-the-emerging) - Carl Hendrick (November 2025)
9. [Supporting Middle School Math with Technology-Based Intervention](https://www.wested.org/resources/middle-school-math-tech-based-intervention/) - WestEd/ASSISTments Study (2024)
