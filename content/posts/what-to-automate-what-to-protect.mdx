---
title: "What to Automate vs. What to Protect: A Leader's Guide"
description: "AI can write your emails, but it can't save your relationships. The 'Stakes vs. Verifiability' framework for deciding when to use a bot."
date: "2025-11-03"
updated: "2026-01-26"
pillar: "leadership"
contentType: "evergreen"
readTime: "9 min read"
featured: true
interlinks:
  - "ai-strategy-leadership"
  - "ai-for-difficult-conversations"
  - "template-library-school-leaders"
---

## The Quiet Concern

When I demonstrate how I automate board reports or parent emails, leaders often pull me aside afterward with the same question:

*"But isn't that... lazy? Am I losing the human touch?"*

It's a legitimate worry. Automate everything and you become a bureaucrat managed by algorithms. Automate nothing and you burn out. I burned out once. It took months to recover. Part of what caused it was exactly this trap—believing every email, every document, every decision required my personal attention.

Most didn't. I just lacked a framework for knowing which ones did.

---

## Why "Easy vs. Hard" Doesn't Work Anymore

Here's what surprised me when I started using AI seriously: the difficulty of a task tells you almost nothing about whether you should automate it.

A 2023 study from Harvard and BCG tested this with 758 consultants ([Dell'Acqua et al., 2023](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321)). Half used GPT-4. Half worked manually. The results were striking:

- Consultants using AI finished tasks **25% faster**
- Their work was rated **40% higher quality**
- But on tasks that fell *outside* AI's capabilities, they performed **19% worse** than those working alone

They trusted the output, missed the nuance, and failed.

The researchers call this the "jagged frontier"—AI capability isn't a smooth line from easy to hard. It's unpredictable. AI can pass the Bar Exam but struggle to count letters in a word. It can write complex code but miss the sarcasm in a parent's email.

For school leaders, this creates a real problem. You can't just hand off "routine" work and assume it's safe. You need a different way to decide.

---

## The Framework: Stakes vs. Verifiability

For years I tried to decide based on complexity. That was a mistake.

A complex task (like analyzing enrollment trends) might be perfectly safe to delegate—I can check the numbers. A simple task (like a two-sentence reply to an upset parent) might be catastrophic to automate—I can't check whether it landed emotionally.

The better question isn't "How hard is this?" It's "How easily can I catch a mistake?"

I now use two questions for every potential AI task:

1. **What's the cost if the AI gets this wrong?**
2. **How quickly can I verify the output?**

<div style={{display: 'grid', gridTemplateColumns: '1fr 1fr', gap: '0', maxWidth: '700px', margin: '2rem auto', border: '2px solid #1e293b', borderRadius: '4px', overflow: 'hidden', fontFamily: 'system-ui, -apple-system, sans-serif'}}>
  <div style={{padding: '1.5rem', backgroundColor: '#f8fafc', borderRight: '1px solid #1e293b', borderBottom: '1px solid #1e293b'}}>
    <div style={{fontSize: '0.7rem', color: '#64748b', textTransform: 'uppercase', letterSpacing: '0.1em', marginBottom: '0.5rem'}}>High Stakes · Easy to Verify</div>
    <div style={{fontSize: '1.1rem', fontWeight: '600', color: '#0f172a', marginBottom: '0.5rem'}}>AUGMENT</div>
    <div style={{fontSize: '0.8rem', color: '#475569'}}>AI drafts. You edit and own.</div>
  </div>
  <div style={{padding: '1.5rem', backgroundColor: '#1e293b', borderBottom: '1px solid #1e293b'}}>
    <div style={{fontSize: '0.7rem', color: '#94a3b8', textTransform: 'uppercase', letterSpacing: '0.1em', marginBottom: '0.5rem'}}>High Stakes · Hard to Verify</div>
    <div style={{fontSize: '1.1rem', fontWeight: '600', color: '#ffffff', marginBottom: '0.5rem'}}>PROTECT</div>
    <div style={{fontSize: '0.8rem', color: '#cbd5e1'}}>The human zone. No delegation.</div>
  </div>
  <div style={{padding: '1.5rem', backgroundColor: '#ffffff', borderRight: '1px solid #1e293b'}}>
    <div style={{fontSize: '0.7rem', color: '#64748b', textTransform: 'uppercase', letterSpacing: '0.1em', marginBottom: '0.5rem'}}>Low Stakes · Easy to Verify</div>
    <div style={{fontSize: '1.1rem', fontWeight: '600', color: '#0f172a', marginBottom: '0.5rem'}}>AUTOMATE</div>
    <div style={{fontSize: '0.8rem', color: '#475569'}}>Let the machine run.</div>
  </div>
  <div style={{padding: '1.5rem', backgroundColor: '#f1f5f9'}}>
    <div style={{fontSize: '0.7rem', color: '#64748b', textTransform: 'uppercase', letterSpacing: '0.1em', marginBottom: '0.5rem'}}>Low Stakes · Hard to Verify</div>
    <div style={{fontSize: '1.1rem', fontWeight: '600', color: '#0f172a', marginBottom: '0.5rem'}}>IGNORE</div>
    <div style={{fontSize: '0.8rem', color: '#475569'}}>Not worth the verification cost.</div>
  </div>
</div>

<div style={{textAlign: 'center', fontSize: '0.75rem', color: '#64748b', marginTop: '0.5rem', marginBottom: '2rem', fontStyle: 'italic'}}>Figure 1: The AI Delegation Matrix</div>

---

### AUTOMATE: Low Stakes, Easy to Verify

**Examples:** Meeting summaries. Calendar scheduling. Formatting data. First-draft brainstorming. Inbox sorting.

If the AI gets it wrong, I see it instantly. No harm done.

No parent feels disrespected when my calendar link sends an automated confirmation. No teacher notices when meeting notes get summarized by AI. These are administrative transactions, not human connections.

I used to spend 20 minutes after every leadership team meeting typing up notes. Now I let Otter.ai draft them and spend 3 minutes scanning for errors. Same output. Fraction of the time.

### AUGMENT: High Stakes, Easy to Verify

**Examples:** Strategic plan drafts. Board presentation outlines. Survey data analysis. Policy first drafts. Budget scenarios.

This is the sweet spot. The stakes are real, but checking the work is easier than doing it from scratch.

Before a Board meeting, I have AI pull enrollment trends, benchmark data, and draft talking points. I review and edit. Preparation time drops from 4 hours to 45 minutes. The final product is still mine—I just didn't start from a blank page.

The Harvard study found that consultants in this zone produced work rated 40% higher quality. Not because AI is smarter than humans, but because it handles the grunt work and lets you focus on judgment.

You become the editor, not the writer. That's a good trade.

### IGNORE: Low Stakes, Hard to Verify

**Examples:** Fact-checking obscure claims. Generating large volumes of unchecked content. Complex calculations without source data.

The effort to verify exceeds the value of the task. You'll spend more time checking than you saved.

Either do it yourself quickly, or decide it doesn't matter enough to do at all. Don't let AI create work for you.

### PROTECT: High Stakes, Hard to Verify

**Examples:** Difficult conversations. Crisis communications. Personnel decisions. The apology. The firing. The vision.

You cannot "verify" a relationship. You have to feel it.

When a parent is furious, they don't want an efficient answer. They want to know a human being is absorbing their anger, considering it, carrying the weight of it.

If you automate that—even if the AI writes a "perfect" empathetic email—you have failed. The value was never the text. The value was the emotional labor of showing up.

I learned this the hard way. Early in my AI experimentation, I let a tool draft a response to a parent complaint. The words were fine. The tone was fine. But something was missing—and the parent knew it. What should have been a 10-minute resolution became a 3-week escalation.

Some messages need to come from your hands, not your tools.

<Callout type="warning" title="The Crumple Zone">
In aviation, the plane's structure is designed to absorb impact and protect the humans inside. In leadership, **you** are the crumple zone. Some moments require you to absorb the weight personally. That's not inefficiency. That's the job.
</Callout>

---

## The Decision Tree

Stop guessing. Run every potential AI task through this logic:

**Can I verify the output in under one minute?**

→ **NO:** Is the cost of being wrong essentially zero?
  - **YES:** Automate anyway (low risk, low reward)
  - **NO:** **PROTECT.** Do not use AI for this.

→ **YES:** Does this require the other person to feel *heard*, not just *informed*?
  - **YES:** **AUGMENT.** Use AI to prepare. You deliver.
  - **NO:** **AUTOMATE.** Let the bot handle it.

The key question isn't "Is this task hard?" It's "Can I catch a mistake before it costs me?"

---

## The 19% Trap

Remember those consultants who performed 19% worse with AI on certain tasks?

They weren't lazy. They were skilled professionals who fell into what researchers call "automation complacency"—when we over-trust automated systems, our own judgment atrophies.

For school leaders, this is the real danger. Not that AI will write something obviously wrong. But that it will write something *subtly* wrong—a tone-deaf phrase, a missing context, a politically naive framing—and you'll miss it because the output looked professional.

I've caught myself doing this. A draft looks polished, so I skim instead of read. Then a colleague points out that the email accidentally promised something we can't deliver. The AI didn't know our budget situation. I did, but I wasn't paying attention.

The matrix isn't about finding tasks you can ignore. It's about allocating your attention intentionally.

---

## Developing Your Own Judgment

Your job is no longer to be the smartest person in the room. AI processes data faster than you ever will.

Your job is to know your context better than any algorithm can.

You need a sense for when the AI is likely to miss something. You need to know that for *this* specific parent, a template email will cause a lawsuit, while for *that* parent, it will be fine. You need to recognize that *this* board member reads every word while *that* one skims for the bottom line.

That judgment—that contextual, relational, political awareness—is the one thing we can't automate. It's also the thing that makes you worth your salary.

<Callout type="tip" title="The question that matters">
Before delegating any task to AI, ask: "If I miss an error in this output, what's the worst realistic consequence?" If the answer makes you uncomfortable, you've found a PROTECT task.
</Callout>

---

## Mapping Your Own Work

The framework only helps if you apply it.

**This week:** List the ten tasks that consumed the most time. For each one, answer: What's the cost of error? How long would verification take?

**This month:** For everything in AUTOMATE, build or find a tool. For everything in PROTECT, stop looking for shortcuts.

**This quarter:** Review your map. Some tasks migrate as your judgment improves. What felt risky six months ago might feel routine now.

The goal isn't maximum automation. The goal is strategic automation—so you have energy left for the work that actually requires you.

<CallToAction text="Get the decision matrix template in the free toolkit" link="/ai-toolkit" />

---

## References

1. Dell'Acqua, F., McFowland, E., Mollick, E., et al. (2023). Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality. *Harvard Business School Working Paper*. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321

2. Mollick, E. (2024). *Co-Intelligence: Living and Working with AI*. Portfolio/Penguin.
