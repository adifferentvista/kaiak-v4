---
title: "What to Automate vs. What to Protect: A Leader's Guide"
description: "AI can write your emails, but it can't save your relationships. Here is the 'Stakes vs. Complexity' framework for deciding when to use a bot."
date: "2025-11-03"
pillar: "leadership"
contentType: "evergreen"
readTime: "8 min read"
featured: false
interlinks:
  - "ai-strategy-leadership"
  - "ai-for-difficult-conversations"
  - "ten-hours-back"
  - "template-library-school-leaders"
---

## The Quiet Concern

When I demonstrate how I automate board reports or parent emails, leaders often pull me aside afterward with the same question:

*"But isn't that... lazy? Am I losing the human touch?"*

It's a legitimate worry.

Automate everything and you become a bureaucrat managed by algorithms. Automate nothing and you burn out. I burned out once. It took months to recover. Part of what caused it was exactly this trap—believing every email, every document, every decision required my personal attention. Most didn't. I just lacked a framework for distinguishing which ones did.

The skill isn't avoiding AI. The skill is knowing **exactly when** to use it.

---

## Stakes vs. Complexity: A Decision Matrix

I use a 2x2 matrix for every automation decision.

{/* [VISUAL SPEC: 2x2 matrix created in a clean design tool. X-Axis: "Complexity" (Low to High). Y-Axis: "Human Stakes" (Low to High). Quadrant labels: Top-Left = "DELEGATE", Top-Right = "PROTECT", Bottom-Left = "AUTOMATE", Bottom-Right = "HYBRID". Use muted colors—not traffic-light red/green. Caption: "The Automation Decision Matrix."] */}

### Quadrant 1: Low Stakes, Low Complexity → AUTOMATE

**Examples:** Scheduling meetings. Sorting inbox. Summarizing meeting notes. Generating routine data reports.

**Principle:** These tasks require no human soul. Hand them to the machine immediately.

No parent feels disrespected when your calendar link sends an automated confirmation. No teacher notices when meeting notes get summarized by AI. These are administrative transactions, not human connections.

*Tools:* Gmail filters, Calendly, Otter.ai, ChatGPT for first-draft summaries.

I've written about reclaiming time through this kind of automation in my [Ten Hours Back](/blog/ten-hours-back) post. Time saved matters less than cognitive space freed.

### Quadrant 2: Low Stakes, High Complexity → DELEGATE

**Examples:** First drafts of policies. Research summaries. Agenda preparation. Benchmark comparisons.

**Principle:** The task requires effort but not your specific judgment. AI handles the heavy lifting; you review and refine.

You're not asking AI to *decide*—you're asking it to *prepare*. The complexity lies in gathering and organizing information, not in the human relationship at stake.

*Example:* Before a Board meeting, I have AI pull enrollment trends, benchmark data, and draft talking points. I review and edit. Preparation time drops from 4 hours to 45 minutes. The final product remains mine—I just didn't start from a blank page.

### Quadrant 3: High Stakes, Low Complexity → DELEGATE (with review)

**Examples:** Routine parent updates during a crisis (facts only). Standard disciplinary documentation. Compliance checklists.

**Principle:** The communication carries weight, but the content is straightforward. Template it, have AI draft it, review before sending.

The stakes are real—a parent receiving information about their child, a teacher receiving documentation about a concern—but the message doesn't require creative judgment. What it requires is accuracy and care.

*Approach:* Use a template. Have AI draft. Read it out loud before sending. If it sounds robotic, revise. If it sounds human, send.

The [Template Library](/blog/template-library-school-leaders) exists for exactly this quadrant. High stakes doesn't mean high effort—it means high attention.

### Quadrant 4: High Stakes, High Complexity → PROTECT

**Examples:** Firing a staff member. Managing a PR crisis. Comforting a grieving family. Negotiating a contract dispute. Mediating serious conflict between teachers.

**Principle:** Do not let a bot send this email. Your physical presence and specific words matter more than efficiency.

These are the moments your job exists for. Anyone can send an email. Only you can sit across from a teacher whose contract you're not renewing and treat them with dignity. Only you can call a parent whose child was injured and convey genuine care.

*Tool of choice:* **Yourself.**

<Callout type="warning" title="Text makes it worse">
The highest-stakes moments are when you're most tempted to hide behind email. A difficult conversation feels easier in writing. It isn't. It's just delayed—and usually made worse.
</Callout>

---

## The Cyborg Approach

Ethan Mollick, a Wharton professor studying AI and work, describes two collaboration models: "Centaur" and "Cyborg" ([Mollick, 2024](https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged)).

**Centaur:** Human and AI work on separate tasks. You decide what AI handles; you handle the rest. Clear division.

**Cyborg:** Human and AI integrate on the same task. AI drafts, you refine. AI researches, you synthesize. Continuous collaboration.

Most leadership work is Cyborg work. The quadrants above help determine *how integrated* the collaboration should be.

**Example: Preparing for a Difficult Conversation**

I never let AI have a difficult conversation for me. That would be cowardly and ineffective.

But I always use AI to prepare.

{/* [VISUAL SPEC: Screenshot of the KAIAK Toolkit showing the 'Difficult Conversation' prompt input area, with a sample context like "I need to tell a vendor we are cancelling their contract. They have been with us for 5 years. I want to be firm but kind." Show the text input, not the output.] */}

I paste the situation into my dashboard:

*"I need to tell a long-time vendor we're ending our contract. They've been with us for five years. I want to be firm but kind."*

AI generates a script. I don't read it verbatim—that would sound hollow.

But reading it clarifies my thoughts. It shows me what I might forget. It lowers my blood pressure. I walk into the room fully present, because I'm not scrambling for words.

The full breakdown of this approach appears in my post on [AI for difficult conversations](/blog/ai-for-difficult-conversations). Automate the *preparation*, protect the *delivery*.

---

## The Complacency Risk

There's a documented phenomenon called "automation complacency"—when we over-trust automated systems, our own monitoring and judgment atrophies ([Parasuraman & Manzey, 2010](https://doi.org/10.1518/001872010X12529674470583)).

For school leaders using AI, this matters.

Let AI write parent communications without careful review, and you'll eventually send something tone-deaf. Let AI summarize meeting notes without checking them, and you'll miss the subtext—the concern that wasn't voiced, the tension that wasn't captured.

The matrix isn't about finding tasks you can ignore. It's about allocating attention intentionally.

**Low-stakes, low-complexity:** Trust and verify quickly.
**High-stakes, any complexity:** Review carefully. Every time.

<Callout type="tip" title="The real question">
Before delegating any task to AI, ask: "Does this recipient need to feel *heard* or just receive the *data*?" Heard = protect. Data = automate. Mixed = hybrid.
</Callout>

---

## Mapping Your Own Work

The matrix only helps if you apply it to actual tasks.

**Week one:** List the ten tasks that consumed the most time last week. Plot each one on the matrix.

**Month one:** For everything in "Automate," find or build a tool. For everything in "Protect," stop looking for shortcuts.

**Quarter one:** Review your map. Has anything shifted? Tasks that felt high-stakes six months ago might feel routine now—and vice versa.

The goal isn't maximum automation. The goal is strategic automation so you have energy left for human work.

---

## Strategic Leadership, Not Lazy Leadership

The leaders who thrive in the next decade won't adopt every AI tool. They'll know when *not* to use them.

Automation multiplies efficiency—but also multiplies mistakes when applied carelessly.

The 2x2 matrix provides a decision framework. The real skill remains judgment: recognizing that this email needs your voice, that meeting needs your presence, that parent needs to see your face.

You automate the boring stuff *so that* you have energy for the human stuff. That's strategic leadership.

<CallToAction text="Get the decision matrix and prompts in the free toolkit" link="/ai-toolkit" />

---

## References

1. Mollick, E. (2024). *Centaurs and Cyborgs on the Jagged Frontier*. One Useful Thing. https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged

2. Parasuraman, R., & Manzey, D. H. (2010). Complacency and bias in human use of automation: An attentional integration. *Human Factors*, 52(3), 381-410. https://doi.org/10.1518/001872010X12529674470583
